# NotebookLM/Canvas Schema Prompt: Digital Office Notion Databases

## Entities (Databases)
- AI Notebook / Knowledge Hub
- Workstreams / Tasks / Content Pieces / Products
- Value-Rules
- AI Systems / AI Projects
- Signals
- Rules (SRME)
- Micro-Habits
- Open Roles
- Candidates
- Companies
- Contacts
- Onboarding To-Dos
- Knowledge Items
- Tech Stack / Tools
- Competitive & Inspirational Benchmarks

## Example Record (AI Systems / AI Projects)
{
  "Name": "Trust Early-Warning System",
  "Risk Level": "High Risk",
  "AI Capability": "Provides conversational insights on culture data",
  "Non-Goals": "Does not replace human decision-making",
  "Decision Rights": "Human approval required for all critical outputs",
  "Guardrails": "System operates within predefined ethical boundaries, no PII stored",
  "Uncertainty UX": "Displays confidence score with each recommendation",
  "Explainability Moments & Depth": "Layered explanations on demand",
  "Fallbacks & Recovery Flows": "Manual override protocol activated if anomaly detected",
  "Metrics": "Accuracy: 92%, User Trust Score: 4.5/5",
  "Logging & Review": "All model-influenced actions are logged for audit",
  "Human Oversight Requirements": "Requires effective human oversight to intervene or halt operations",
  "Technical Documentation": "Transparency Dossier_CultureCopilot_v1.0.pdf",
  "Data Governance Plan": "Data Governance Dossier_TrustEW_v1.0.pdf",
  "Bias Assessment/Mitigation": "Bias monitoring and mitigation plan in place",
  "Accuracy Metrics": 0.95,
  "Cybersecurity Measures": "Includes robust encryption and access controls",
  "Adversarial Testing Results": "Red Team Report_GenAI_Q3.pdf",
  "Post-Market Monitoring Plan": "Post-Market Monitoring_CultureCopilot.pdf",
  "Generative AI Risks": ["Hallucination", "Data Poisoning"],
  "Fundamental Rights Impact Assessment (FRIA)": true,
  "Environmental Impact (Energy Consumption)": 500,
  "Specific Human Oversight Protocols": "HOS_Protocol_HR_AI.pdf",
  "Bounded Autonomy Framework": "BoundedAutonomy_AICoach.pdf",
  "Compliance Roadmap": "Compliance Roadmap_Q4-2025.pdf"
}

## Relationships
- Workstreams / Tasks ↔ Team (many-to-one)
- Workstreams / Tasks ↔ Person (RACI) (many-to-many)
- Workstreams / Tasks ↔ Value-Rules (many-to-many)
- AI Systems / AI Projects ↔ Value-Rules (many-to-many)
- Signals ↔ Data Type (many-to-one)
- Signals ↔ Domain Anchor (many-to-many)
- Signals ↔ Value-Rules (many-to-many)
- Rules (SRME) ↔ Value-Rules (many-to-one)
- Rules (SRME) ↔ Micro-Habits (one-to-many)
- Open Roles ↔ Candidates (one-to-many)
- Contacts ↔ Companies (many-to-one)
- Knowledge Items ↔ Teams (many-to-many)
- Tech Stack / Tools ↔ Teams (many-to-many)
- AI Systems / AI Projects ↔ Tech Stack / Tools (many-to-many)
- Workstreams / Tasks ↔ Google Calendar Events (many-to-many)
- Contacts ↔ Google Calendar Events (many-to-many)

## Instructions
- Use the above entities, properties, and relationships to design interconnected Notion databases and pages for a digital office.
- Each entity should be a Notion database with the specified properties.
- Use the relationships to create Notion relations and rollups.
- Use the example record as a template for data entry.
- Refer to the detailed property types and examples for each entity as needed.
- This schema is ready for import or adaptation in NotebookLM and Canvas workflows.

# NotebookLM/Canvas Schema Full Prompt: Digital Office Notion Databases

To design interconnected Notion databases and pages for a digital office, drawing on the provided sources, here are the detailed, source-grounded facts:
1) ENTITIES (Databases we need)
AI Notebook / Knowledge Hub - A central repository for documentation, project tracking, and a library for AI prompts.
Example Records: "AI prompt for market analysis", "Q3 Project Roadmap", "AIX Heuristics Documentation", "Ethical AI Guidelines".
Workstreams / Tasks / Content Pieces / Products - Tangible outcomes and activities created by teams.
Example Records: "AIX Heuristics Development", "Podcast Episode 1 Script", "Q4 Marketing Strategy", "SaaS Platform v1.0".
Value-Rules - The core principles and guiding behaviors for daily work.
Example Records: "Psychological Safety", "Continuous Improvement", "Transparency", "Integrity", "Kindness".
AI Systems / AI Projects - Descriptions and management of AI systems being developed or deployed.
Example Records: "Culture Copilot v1", "Trust Early-Warning System", "Generative AI Content Labeler", "Policy Simulator".
Signals - Measurable inputs that contribute to the Culture Homeostasis Index (CHI).
Example Records: "Meeting Sentiment Score", "Employee Learning & Development Activity", "Cross-Project Collaboration Frequency", "External Brand Sentiment".
Rules (SRME) - Proposed behavioral rules generated by the Semantic Rule Matching Engine (SRME).
Example Records: "Use hand-raise in meetings", "Daily 15-min retro with one fix committed", "Requests must include context/purpose".
Micro-Habits - Small, repeatable actions suggested by the SRME.
Example Records: "DM one teammate daily for unfiltered input", "Log one 1% improvement each day", "Reflect back the ask before replying".
Open Roles - Positions being recruited for.
Example Records: "Head of AI Governance", "AI Czar", "MLOps Engineer", "Content Creator".
Candidates - Individuals applying for open roles.
Example Records: "Jane Doe (Senior AI Engineer)", "John Smith (Marketing Specialist)", "Alice Brown (AI Coach)".
Companies - Organizations related to contacts.
Example Records: "Colibri Partners", "Acme Corp", "Innovate Solutions".
Contacts - Individuals in the CRM, for recruiting and outreach.
Example Records: "Dr. Elena Petrova (AI Ethicist)", "Mr. David Chen (Product Manager)", "Ms. Sarah Lee (Investor)".
Onboarding To-Dos - Goals and tasks for new team members.
Example Records: "Complete Notion Features Checklist", "Review RACI System", "Interactive Workspace Tour", "Set up OnePassword".
Knowledge Items - New information, ideas, links, or files captured for the "Knowledge Garden".
Example Records: "Article: Future of AI Governance", "Presentation: TEAL Principles", "User Feedback Survey Results", "AI Act Summary PDF".
Tech Stack / Tools - The collection of software and platforms used by the organization.
Example Records: "Notion Business Plan", "HubSpot Sales Hub Professional", "OnePassword Teams Starter Pack", "Fathom Team Plan".
Competitive & Inspirational Benchmarks - Organizations identified for competitive analysis or as sources of inspiration.
Example Records: "Culture Amp", "ETH AI Center", "OrgMapper", "i4cp".
2) PROPERTIES (per Entity)
AI Systems / AI Projects
Name (title) - Name of the AI system or project. Example: "Trust Early-Warning System".
Risk Level (select) - Classification based on EU AI Act (Unacceptable, High, Limited, Minimal). Example: "High Risk".
AI Capability (rich_text) - Description of what the AI system can do. Example: "Provides conversational insights on culture data".
Non-Goals (rich_text) - What the AI system is explicitly not designed to do. Example: "Does not replace human decision-making".
Decision Rights (rich_text) - Who decides, when. Example: "Human approval required for all critical outputs".
Guardrails (rich_text) - Safety, privacy, scope limitations. Example: "System operates within predefined ethical boundaries, no PII stored".
Uncertainty UX (rich_text) - How confidence levels and alternatives are presented to users. Example: "Displays confidence score with each recommendation".
Explainability Moments & Depth (rich_text) - When and how explanations are provided. Example: "Layered explanations on demand".
Fallbacks & Recovery Flows (rich_text) - Procedures in case of malfunction. Example: "Manual override protocol activated if anomaly detected".
Metrics (rich_text) - Quality, trust, speed, safety metrics. Example: "Accuracy: 92%, User Trust Score: 4.5/5".
Logging & Review (rich_text) - Forensics, auditability. Example: "All model-influenced actions are logged for audit".
Human Oversight Requirements (rich_text) - Mandatory measures to intervene or halt operations. Example: "Requires effective human oversight to intervene or halt operations".
Technical Documentation (files) - Detailed documentation for high-risk systems. Example: "Transparency Dossier_CultureCopilot_v1.0".
Data Governance Plan (files) - Plan covering data acquisition, management, documentation. Example: "Data Governance Dossier_TrustEW_v1.0".
Bias Assessment/Mitigation (rich_text) - Monitoring and mitigation of discriminatory outcomes. Example: "Bias monitoring and mitigation plan in place".
Accuracy Metrics (number) - From testing. Example: "Accuracy: 0.95".
Cybersecurity Measures (rich_text) - Measures implemented. Example: "Includes robust encryption and access controls".
Adversarial Testing Results (files) - Results from red teaming. Example: "Red Team Report_GenAI_Q3".
Post-Market Monitoring Plan (files) - For tracking performance and risks. Example: "Post-Market Monitoring_CultureCopilot".
Generative AI Risks (multi_select) - Potential for hallucination, data poisoning, malicious use, copyright infringement. Example: "Hallucination, Data Poisoning".
Fundamental Rights Impact Assessment (FRIA) (checkbox) - Conducted for contexts specified by EU AI Act.
Environmental Impact (Energy Consumption) (number) - Estimated energy consumption for model training and inference. Example: "500 kWh".
Specific Human Oversight Protocols (files) - Detail intervention triggers, fallback procedures, training for overseers. Example: "HOS_Protocol_HR_AI".
Bounded Autonomy Framework (files) - Pre-defines scope of action, decision thresholds, monitoring for anomalous behavior (for Agentic AI). Example: "BoundedAutonomy_AICoach".
Compliance Roadmap (files) - Steps and timelines for achieving and maintaining compliance. Example: "Compliance Roadmap_Q4-2025".
Signals
Signal Input (title) - Description of the data point. Example: "Meeting sentiment".
Data Type (select) - Think, Say, Do, Feel. Example: "Say".
Source View (select) - Internal / External. Example: "Internal".
Weight Score (number) - Fibonacci-based (1, 2, 3, 5). Example: "3".
Impact Level (select) - Micro, Meso, Macro, Mundo. Example: "Meso".
Confidence Notes (rich_text) - Factors affecting score reliability. Example: "High with repeated entries and task matching".
Domain Anchor (multi_select) - Human / Organizational / Operational / Environmental. Example: "Human, Organizational".
Formula (rich_text) - Mathematical formula for the signal. Example: "meetings_with_dissent / total_meetings".
Description (rich_text) - Detailed explanation of the signal. Example: "Share of meetings with ≥1 dissent recorded before decision".
Value-Rules
Name (title) - Name of the value rule. Example: "Psychological Safety".
Exact Wording (rich_text) - Precise definition. Example: "Take responsibility for your needs, triggers and blind spots" (for Self-awareness).
Anti-examples (rich_text) - Examples of behavior that goes against the value.
Description (rich_text) - Explanation of the value. Example: "Being open-minded and willing to learn. It involves asking open questions to understand, seeking out new information, and being genuinely receptive to different perspectives." (for Curiosity).
Rules (SRME)
Trigger (title) - Culturally-relevant tension or friction. Example: "Low dissent rate in meetings".
Value (relation) - Organizational value this rule aligns with. Example: "Psychological Safety".
Impact Level (select) - Micro, Meso, Macro, Mundo. Example: "Micro".
Rule (rich_text) - Clear behavior aligned with the value. Example: "Leader prompts for 2 dissenting views first".
NLP-derived Keywords (multi_select) - Keywords used to compute relevance and rule fit.
Micro-Habits
Micro-habit (title) - Small, repeatable action. Example: "DM one teammate daily for unfiltered input".
Related Rule (relation) - The SRME rule this micro-habit is associated with.
Related Value (relation) - The value this micro-habit supports.
Open Roles
Role Name (title) - Name of the open position. Example: "Head of AI Governance".
Status (status) - Chaordic Status Taxonomy (Green, Yellow, Blue, Red, Black, White). Example: "Blue (Planning)".
Team (select) - Team responsible for this role (Admin, Tools, Culture, Council, Products, Media, Research). Example: "Admin Team".
Focus (rich_text) - Primary areas of responsibility. Example: "Legal, Finance, Strategy, Recruitment".
Key Activities (rich_text) - Key tasks involved. Example: "Managing shareholder agreements, designing financial processes".
Candidates
Full Name (title) - Candidate's full name. Example: "Jane Doe".
Status (status) - Chaordic Status Taxonomy (Green, Yellow, Blue, Red, Black, White). Example: "Green (Active)".
Open Role (relation) - Related open role. Example: "Head of AI Governance".
Folk Person ID (rich_text) - Unique identifier from Folk. Example: "fp_12345".
Email (email) - Candidate's email address. Example: "jane.doe@example.com".
Phone (phone) - Candidate's phone number. Example: "+41 79 123 45 67".
Company (relation) - Related company from the Companies database. Example: "Acme Corp".
Notion Record ID (formula) - Unique ID of the Notion page (id()). Example: "a1b2c3d4e5f6g7h8".
Companies
Name (title) - Company's name. Example: "Colibri Partners".
Folk Company ID (rich_text) - Unique identifier from Folk. (UNKNOWN – needs decision).
Workstreams / Tasks / Content Pieces / Products
Name (title) - Name of the work item. Example: "AIX Heuristics Development".
Status (status) - Chaordic Status Taxonomy. Example: "In Progress (Green)".
Team (select) - Responsible team. Example: "Products Branch".
Responsible (R) (people) - The doer(s). Example: "Maria".
Accountable (A) (people) - The steward (single owner). Example: "Esteve".
Consulted (C) (people) - The helper(s). Example: "Hash".
Informed (I) (people) - The learner(s). Example: "Kersten".
Content Type (select) - Type of work (e.g., SaaS Platform, Consultancy, Courses, Website, Podcast, Video Shorts, Literature Review, Competitor Analysis, AIX Research). Example: "SaaS Platform".
Client/Coachee (rich_text) - Used in naming convention. Example: "Colibri".
Environment (rich_text) - Used in naming convention. Example: "Dev".
Version (rich_text) - Used in naming convention. Example: "v1.0".
Date (date) - Used in naming convention. Example: "21082025".
Start Date (date) - Start date of the task/event. Example: "2025-09-01".
End Date (date) - End date of the task/event. Example: "2025-09-05".
Description (rich_text) - Details of the task/event. Example: "Develop core features for platform".
Attendees (people) - People attending the event (for calendar-synced items). Example: "Steven, Esteve".
GCal Event ID (rich_text) - Unique ID of the corresponding Google Calendar event. Example: "gcal_event_id_xyz".
Last Edited Time (date) - Automatically updates when an item is changed (for Zapier sync). Example: "2025-09-09 14:30".
Related Value-Rules (relation) - Aligns with specific Value-Rules. Example: "Continuous Improvement".
Onboarding To-Dos
Goal/Task Name (title) - Name of the goal or task. Example: "Notion Features Checklist".
Assigned Person (people) - The new team member. Example: "Maria".
Status (status) - Chaordic Status Taxonomy. Example: "Green (Go, Active)".
Description (rich_text) - Details or interactive content. Example: "Interactive checklist of Notion features and templates to learn".
Knowledge Items
Name (title) - Title of the knowledge item. Example: "AI Governance Principles Consolidation".
Type (select) - Link, File, Insight. Example: "File".
Tags (multi_select) - Relevant teams and research taxonomy tags ([Insight], [DataPoint], [Quote], [CaseStudy], [ActionItem], [Contact]). Example: "Research Lab, [Insight], [DataPoint]".
URL (url) - URL if the item is a link. Example: "https://example.com/aigov-report".
File (files) - Attached file if applicable. Example: "AI_Governance_Report.pdf".
Summary/Notes (rich_text) - Summary or notes about the item. Example: "Key findings on AI Act alignment and NIST RMF".
Tech Stack / Tools
Tool Name (title) - Name of the tool. Example: "Notion".
Strategic Purpose (rich_text) - Function within Colibri's workflow. Example: "Acts as the company's 'second brain' for documentation, project tracking, and a centralized library for AI prompts".
Plan/Edition (select) - Subscription plan or edition. Example: "Business".
Seats/Licenses (number) - Number of seats or licenses. Example: "6".
Billing Cycle (select) - Annual, Monthly, One-Time. Example: "Annual".
Cost per Unit/Month (number) - Cost per seat/license per month. Example: "$20.00".
First-Year Annual Cost (number) - Total annual cost for the first year. Example: "$1,440.00".
Status (select) - Up & Running, To Investigate, To Buy or Change, Idea, Check with Team. Example: "Up & Running".
Tool Category (select) - Core Productivity & AI, Knowledge Management, Rapid Prototyping, Workflow Automation, Structured Data Intake, Security & Access, Platform Database & Workflows, Interaction Design (Asynchronous Tools), Sales, Research, Recruiting & Investor Networking, Paygates & Domains. Example: "Knowledge Management".
Competitive & Inspirational Benchmarks
Company/Service Name (title) - Name of the benchmark. Example: "Culture Amp".
Website URL (url) - URL of the company website. Example: "https://www.cultureamp.com/".
Logo URL (url) - URL of the company logo. Example: "https://images.ctfassets.net/64fde84d02a3d7e8a1e2f4927885b328/4F2213A5308291.55406180/culture-amp-logo-1.svg".
Category (select) - Direct Competitor, Inspirational Benchmark. Example: "Direct Competitor".
Sub-Category (select) - Employee App / Comms, HRIS, Culture Consulting, People Analytics / ONA, AI Governance / Ethics, Community Hub, Employee Experience, Performance Management, HCM Suite, Experience Management. Example: "Employee Experience".
Rationale for Inclusion (rich_text) - Reason for including as a benchmark. Example: "The definitive market leader in the employee experience category, setting the global standard".
3) RELATIONSHIPS
Workstreams / Tasks ↔ Team: Many-to-one, indicating which team is responsible for a work item.
Workstreams / Tasks ↔ Person (RACI): Many-to-many, defining Responsible, Accountable, Consulted, and Informed parties for each work item.
Workstreams / Tasks ↔ Value-Rules: Many-to-many, showing which value rules guide the work.
AI Systems / AI Projects ↔ Value-Rules: Many-to-many, ensuring compliance with ethical principles.
Signals ↔ Data Type: Many-to-one, classifying signals into Think, Say, Do, Feel.
Signals ↔ Domain Anchor: Many-to-many, associating signals with cultural domains (Human, Organizational, Operational, Environmental).
Signals ↔ Value-Rules: Many-to-many, as signals are used to measure the manifestation of value rules.
Rules (SRME) ↔ Value-Rules: Many-to-one, as SRME rules are generated based on a selected organizational value.
Rules (SRME) ↔ Micro-Habits: One-to-many, where one rule can suggest multiple micro-habits.
Open Roles ↔ Candidates: One-to-many, linking candidates to the roles they apply for.
Contacts ↔ Companies: Many-to-one, linking contacts to their associated company.
Knowledge Items ↔ Teams: Many-to-many, for tagging relevant teams that a knowledge item pertains to.
Tech Stack / Tools ↔ Teams: Many-to-many, specifying which teams utilize particular tools.
AI Systems / AI Projects ↔ Tech Stack / Tools: Many-to-many, for integrations, monitoring tools, or underlying technology.
Workstreams / Tasks ↔ Google Calendar Events: Many-to-many, where tasks can be represented as events and synced.
Contacts ↔ Google Calendar Events: Many-to-many, as meetings with contacts are events tracked in the calendar.
4) PAGE TYPES (non-database content)
README.md: High-level overview of the project, how to navigate the repository, and key contacts.
Values.md: Clearly define core "Value-Rules" with exact wording, thresholds, and examples.
Data_dictionary.md: Specify signal formulas, data sources, and detailed confidence rules.
Governance.md: Outline roles, cadences, alert mechanisms (e.g., Z-score guardrails), and an audit trail.
Changelog.md: Document learnings and changes from dry-runs and iterations.
AI-X One-Pager: Definition, scope, principles, and governance of AI-X.
AI-UX Spec: Template for every AI feature, covering problem, users, AI capability, decision rights, guardrails, etc..
Rules of Engagement: Decision rights, autonomy levels, override/rollback rules for AI interactions.
Culture Impact Study Plan: Metrics list, survey items, and difference-in-differences (DID) design for culture impact studies.
Onboarding Space: Dedicated pages within primary team Notion pages for new team members.
Overall Company Roadmap: Establishing the overall company roadmap.
Financial Processes Guidelines: Designing financial processes.
File Structures and Naming Conventions: Defining file structures and naming conventions.
Security Protocols Documentation: Managing security protocols.
Team Culture Workshops Content: Designing team culture workshops.
Micro-habits Library: Developing micro-habits for the team.
Council Needs and Member Roles/Responsibilities: Identifying needs for the council, approaching members, and establishing roles.
Product Portfolio Overview: Managing the product portfolio.
Consultancy Toolkits: Building out consultancy toolkits.
Learning Content: Creating learning content.
Brand and Logo Guidelines: Developing and launching the brand and logo.
Marketing Strategy Documents: Designing the marketing strategy.
Social Media Channel Strategy: Managing social media channels.
Website Content / Podcast Scripts / Video Short Scripts: Creating content for media.
Literature Reviews: Conducting literature reviews.
NotebookLM Sources: Structured knowledge exported from Notion for use in LLMs.
Founders' Agreement: Legal document outlining roles, equity, decision-making, and provisions for departure.
Bounded Autonomy Framework: Pre-defines system's scope of action, decision-making thresholds for human review, and monitoring for anomalous behavior for Agentic AI.
Human Oversight Protocols: Detail specific intervention triggers, documented fallback procedures, and required AI literacy/training for overseers.
Process-Based Transparency Protocol: Documentation of data provenance, content watermarking, and clear disclaimers for Generative AI.
AI Accountability Map: Explicitly names individuals and teams responsible for each stage of the AI lifecycle.
Robustness and Security File: Documents how AI systems meet requirements of Article 15 of the EU AI Act.
Compliance Roadmaps: Outline specific steps and timelines for achieving and maintaining compliance with regulations.
AI Governance Framework: Maintaining and updating the AI governance framework.
Post-Market Monitoring Plan: For all high-risk AI systems, specifies data, frequency, metrics, and triggers for corrective action.
Regulatory Intelligence Function Documentation: Responsible for tracking global AI regulatory landscape and recommending policy updates.
Legal and Ethical Impact Assessment (LEIA) Template: Incorporates specific requirements of a FRIA where applicable.
AI-UX Stack Layers Explanation: Details the five layers (Data → Model → Capability → Affordance/UI → Outcome) for AI design.
Survey Items (AI-X): Likert 1-7 items to assess AI-X in the organization.
Trust Score Formula Explanation: Details the pragmatic composite formula for trust.
Raw Fibonacci Output: Documents raw Fibonacci-based scores.
Mathematical Details: Core equations for CHI calculation.
GDPR Raw Data Labels: Official GDPR data labels for CIO and other data users.
5) VIEWS/WORKFLOWS
Project Tracking Boards: Kanban boards, calendars, lists, or Gantt-style timelines for workstreams and tasks.
Example: "Q3 Project Roadmap by Status" (Kanban board).
Recruiting Pipeline: Dedicated Notion databases for "Open Roles" and "Candidates" with statuses color-coded.
Example: "Candidates by Stage" (Kanban board, grouped by 'Open Role').
Onboarding Workflows: Personalized "My To-Do" view pre-filtered for new users.
Example: "My Onboarding Tasks (Maria)" (List view, filtered by 'Assigned Person').
Knowledge Ingestion Workflow ("Watering the Tree"): Central Notion Form for quickly capturing information (links, files, insights) and tagging relevant teams.
Example: "New Knowledge Submissions" (Table view, sorted by 'Date Added', filtered by 'Tags').
AI System Risk Classification Process: Mandatory intake assessment to classify AI projects against EU AI Act criteria, recorded in a central AI system inventory.
Example: "AI Systems by Risk Level" (Gallery view, grouped by 'Risk Level').
Explainability Triage System: Differentiates transparency requirements based on EU AI Act's risk tiers, with varying levels of disclosure.
Example: "AI Systems (Transparency Review)" (Table view, filtered by 'Risk Level', showing 'Transparency Dossier' link).
Fairness and Bias Review Gate: Mandatory review for high-risk systems before deployment, documenting outcomes for audit purposes.
Example: "High-Risk AI Systems (Fairness Review Status)" (Table view, filtered by 'Risk Level: High', showing 'Fairness and Bias Review' column).
Post-Incident Review Process: For AI-related safety/security events, systematically feeding findings back into design and development.
Example: "AI Incident Log" (Table view, sorted by 'Date', showing 'Post-Incident Review' status).
Z-score Alerts and Owner Routing: Operationalizes feedback loops for early detection of cultural imbalances, nudging owners at -1σ and escalating at -2σ.
Example: "Culture Health Alerts" (Table view, filtered by 'Z-score <= -1', showing 'Domain Anchor' and 'Assigned Owner' relation).
Culture Homeostasis Index (CHI) Dashboards:
Team Leads: CHI dashboard with live and forecasted risk areas.
Example: "Team Alpha CHI Overview" (Dashboard, showing 'CHI Trend', 'Say-CHI Trend', 'Dissent-to-Decision Ratio').
Org Leaders: CHI heatmap with strategic risk areas by quarter, CHI drift over time.
Example: "Organizational Culture Heatmap" (Gallery view, grouped by 'Quarter', with 'CHI Status' as cover image).
Individuals: Micro-habits, calendar nudges via Flow AI Coach.
Example: "My Daily Nudges" (List view, filtered by 'Assigned Person', sorted by 'Date').
Comms/Brand/ESG: Narrative heatmap, external sentiment.
Example: "Brand & Culture Alignment" (Table view, showing 'Value Alignment Score', 'External Brand Sentiment').
AI Coach: Uses patterns to personalize nudges & habits system-wide.
Example: "SRME Rules & Micro-Habit Library" (Table view, filtered by 'Impact Level', showing 'CHI Impact Score').
Google Calendar Sync: Two-way sync with Notion databases for tasks and events.
Example: "Synced Calendar Events" (Calendar view, displaying Notion tasks as events and Google Calendar events).
Folk CRM Sync: Two-way contact sync (via Zapier/Make.com workaround) between Folk and Notion.
Example: "All Contacts" (Table view, showing 'Full Name', 'Email', 'Company', 'Folk Person ID').
Tech Stack Inventory: Tracking tools, plans, costs, and strategic purpose.
Example: "Active Tech Stack (2025)" (Table view, showing 'Tool Name', 'Plan', 'Annual Cost', 'Strategic Purpose').
Competitor/Benchmark Analysis: Interactive overview of competitive and inspirational ecosystems.
Example: "Benchmarks by Category" (Gallery view, grouped by 'Category' and 'Sub-Category').
6) RULES & TAXONOMIES
TEAL Principles: Self-management, wholeness, evolutionary purpose.
Colibri's 9 Value-Rules:
Respect: "No Judgement".
Kindness: "It's kind to ask for help".
Privacy: "What is Shared Stays in the Group" (circle of trust).
Self-awareness: "Host Yourself" / "Take responsibility for your needs, triggers and blind spots".
Curiosity: "Listen to Understand".
Humility: "Ask and Thank for Feedback" / "Ask and thank for conscious feedback".
Collective intelligence: "Ask Uniting Questions" / "Ask uniting questions" (e.g., How Might We…?).
Social Learning: "Own or Check Assumptions" / "Own or Check your Assumptions".
Transparency: "Speak with clear intentions and purpose".
Chaordic Status Taxonomy (Color-Coded):
🟢 Green: Go, Active.
🟡 Yellow: Paused, Pending.
🔵 Blue: Planning, To Do.
🔴 Red: Blocked, Needs Help.
⚫ Black: Done, Archived.
⚪ White: Idea, Backlog.
Naming Convention (ADHD-Friendly): Format: [Client/Coachee]_[ContentType]_[Environment]_v[Version]_[DDMMYYYY].
RACI Workstream Triads: R (Responsible: The Doer(s)), A (Accountable: The Steward (single owner)), C (Consulted: The Helper(s)), I (Informed: The Learner(s)).
Chaordic Roles: Expert (Default), Harvester, Host, Steward.
CHI Impact Levels (Fibonacci-based): Micro (1), Meso (3), Macro (8), Mundo (21).
Do/Think/Say/Feel Weights (Fibonacci-based): Feel (5), Say (3), Do (2), Think (1).
Confidence Score Calculation: Confidence Score = f(Data Volume, Recency, Variance, Source Redundancy).
Abaque de Régnier Color Coding System (for data classification/cleaning): Dark green (completely agree), Light green (agree), Orange (uncertain or mixed), Light red (disagree), Dark red (completely disagree), White (don’t know), Black (not respond at all).
Z-score Guardrails (for alerts):
-1σ: Emerging tension (nudge owners).
-2σ: Critical (escalate to Org Leader + publish SRME rule).
+2σ: Thriving (capture micro-habit as pattern library entry).
Feedback Frequency (Fibonacci intervals): Daily nudges (1 day), Reflective pulse (2 days), Team sync (3 or 5 days), Deep dive (8 or 13 days).
Research Tagging Taxonomy for Export: [Insight], [DataPoint], [Quote], [CaseStudy], [ActionItem], [Contact].
AI Risk Classification (EU AI Act): Unacceptable Risk (banned), High Risk (heavily regulated), Limited Risk (transparency obligations), Minimal Risk (no additional legal obligations).
AI-UX Stack: 5 layers: Data → Model → Capability → Affordance/UI → Outcome.
AI-X Heuristics (7): Make uncertainty legible, Default to reversible actions, Offer layered explanations, Bound autonomy + clear decision rights, Human-in/on/over-the-loop by context, Privacy-by-design & consent-aware interactions, Fail safely with graceful recovery.
AI Interaction Patterns: Advisor (suggest), Co-pilot (co-create), Delegate (act with bounds), Supervisor (check/approve). Always include: preview → confirm → execute → undo.
Trust Score Formula: T = w₁·Predictability + w₂·Competence + w₃·Integrity + w₄·Benevolence – Penalties (surprises, irreversibility, opacity).
GDPR Raw Data Labels: All data labels for the CIO and other data users.
7) OPEN QUESTIONS
Homeostasis Coefficient Definition: The document states " Describe this data point in format and tabulation," indicating a need for a clear definition and structured format.
Notion's Role as CRM/PM Hub: One source suggests Notion is unsuitable as a primary CRM/PM hub due to missing native features and lack of two-way Google Calendar sync. However, another source lists Notion as the "Main prompt library, documentation hub, project tracking" and suggests it can be used for "goal setting, status tracking, and lead management". This ambiguity requires a decision on the scope of Notion's project management and CRM capabilities and how they integrate with a dedicated CRM like HubSpot or Folk.
Folk's Role in Tech Stack: One recommendation is to integrate Folk for multi-channel recruiting, while another source disagrees with Folk as a primary hub, suggesting HubSpot instead. A decision is needed on whether Folk will be integrated, and if so, its precise function and relationship to other CRM/PM tools.
Integration for AI Agent Options: The "Tech Stack V2" document lists "AI agent option (eg. Salesforces' AI Agent) To Investigate", indicating a pending decision on specific AI agent tools.
Paygates & Domains: The status for "PAYGATES & DOMAINS" is listed as "Unknown", requiring clarification and decision-making for these elements.
Flexible No-Code Database: A "DATABASE – Flexible no-code database for tracking prompts, coaching data, scripts" is listed as an "Idea", indicating a need to decide on its implementation and integration.
Additional Asynchronous/AI Tools: Several tools like Loom, Airtime, Videoask, Later.com, 11Labs, Kondo, ChatGPT Pro, Perplexity, and Claude are listed as "To Investigate" or "Idea", requiring decisions on their adoption and integration.
Figma Design System Integration: "Figma Design System (Front End)" is listed as "Up & Running". A decision might be needed on how its design components are documented and linked within Notion pages and databases.
Notion Calendar Limitations: Notion Calendar functions as a "unified viewer" but lacks true bi-directional sync from Google Calendar to Notion databases, preventing full centralization of event data within Notion for project management. A decision is needed on whether to rely on external sync services (e.g., 2sync) or accept this limitation.
Zapier/Make.com Complexity for Bi-directional Sync: Achieving robust two-way sync with these platforms is complex, requires building multiple workflows, and is prone to data duplication, infinite loops, and "maintenance debt". This requires a decision on whether to accept this complexity and maintenance burden or invest in dedicated sync services or custom API development.
Notion Relation Property Workaround: The Notion connector in Zapier cannot directly create or update Relation properties, necessitating an advanced "Code by Zapier" or "Webhooks" workaround for CRM integration. A decision is needed on the acceptable level of technical complexity for implementing this workaround.
Capital Efficiency Target Discrepancy: The projected first-year Total Cost of Ownership (TCO) for the recommended tech stack ($22,118.04) achieves a capital efficiency of ~6.8x, which is significantly lower than the target of 40x. This requires stakeholder input on adjusting the efficiency target or feature set.

